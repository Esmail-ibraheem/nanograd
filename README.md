# omniGPT                                                  
The fastest and most efficient repository for fine-tuning GPTs, implementing various PEFT techniques like LoRA and adapters, as well as quantization, FlashAttention, and sentiment analysis using PPO.
  
## omniGPT overview:
<p align="center"> <img src="https://github.com/Esmail-ibraheem/omniGPT/blob/main/assets/omniGPT-architecture.drawio.svg" alt="omniGPT overview" ></p> 

## GPT architecture:
<p align="center"> <img src="https://github.com/Esmail-ibraheem/omniGPT/blob/main/assets/GPT.jpeg" alt="GPT architecture overview" ></p> 

## fine-tuning (PEFT):
<p align="center"> <img src="https://github.com/Esmail-ibraheem/omniGPT/blob/main/assets/LoRAoverview.jpeg" alt="LoRAs" ></p> 
